# ===========================================
# Fehres - Environment Configuration
# ===========================================
# Copy this file to .env and fill in real values

APP_NAME="Fehres"
APP_VERSION="0.1"

# ===========================================
# File Processing Settings
# ===========================================
FILE_ALLOWED_TYPES = ["text/plain", "application/pdf", "text/markdown", "text/x-markdown", "application/json", "text/csv", "application/vnd.openxmlformats-officedocument.wordprocessingml.document", "application/octet-stream"]
FILE_MAX_SIZE = 10
FILE_DEFAULT_CHUNK_SIZE = 512000

# ===========================================
# PostgreSQL Database
# ===========================================
POSTGRES_USER = "postgres"
POSTGRES_PASSWORD = "your-postgres-password"
POSTGRES_HOST = "localhost"
POSTGRES_PORT = "5433"
POSTGRES_MAIN_DB = "fehres"

# ===========================================
# LLM Configuration
# ===========================================
GENRATION_BACKEND = "GEMINI"
EMBEDDING_BACKEND = "GEMINI"

# API Keys (fill in your own)
OPENAI_API_KEY = "your-openai-api-key"
OPENAI_BASE_URL = "https://api.openai.com/v1"
COHERE_API_KEY = "your-cohere-api-key"
GEMINI_API_KEY = "your-gemini-api-key"

GEMINI_API_VERSION = "v1beta"
OLLAMA_BASE_URL = "http://localhost:11434"
HUGGINGFACE_API_KEY = "your-huggingface-api-key"

# Ollama (local) example:
# GENRATION_BACKEND = "OLLAMA"
# EMBEDDING_BACKEND = "OLLAMA"
# GENRATION_MODEL_ID = "qwen3:8b"
# EMBEDDING_MODEL_ID = "qwen3-embedding:8b"
# EMBEDDING_SIZE = 768

# HuggingFace example:
# GENRATION_BACKEND = "HUGGINGFACE"
# EMBEDDING_BACKEND = "HUGGINGFACE"
# HUGGINGFACE_API_KEY = "hf_your_token_here"
# GENRATION_MODEL_ID = "meta-llama/Llama-2-7b-chat-hf"
# EMBEDDING_MODEL_ID = "sentence-transformers/all-MiniLM-L6-v2"
# EMBEDDING_SIZE = 384


# Model Configuration
GENRATION_MODEL_ID_LITERAL = ["gemini-2.5-flash", "command-r-plus-08-2024", "gpt-3.5-turbo-0125"]
EMBEDDING_MODEL_ID_LITERAL = ["text-multilingual-embedding-002", "text-embedding-002", "text-embedding-004"]
GENRATION_MODEL_ID = "gemini-2.5-flash"
EMBEDDING_MODEL_ID = "text-multilingual-embedding-002"
EMBEDDING_SIZE = 768


# Generation Parameters
INPUT_DEFUALT_MAX_CHARACTERS = 768
GENRATED_DEFUALT_MAX_OUTPUT_TOKENS = 8196
GENRATION_DEFUALT_TEMPERATURE = 0.1

# ===========================================
# Vector Database
# ===========================================
VECTORDB_BACKEND_LITERAL = ["QDRANT", "PGVECTOR"]
VECTORDB_BACKEND = "PGVECTOR"
VECTORDB_PATH = "qdrant_DB"
VECTORDB_DISTANCE_METHOD = "cosine"
VECTORDB_PGVEC_INDEX_THRESHOLD = 4

# ===========================================
# Language Settings
# ===========================================
PRIMARY_LANGUAGE = "en"
DEFUALT_LANGUAGE = "en"

LEARNING_BOOKS_CHUNK_SIZE = 2000
LEARNING_BOOKS_OVERLAP_SIZE = 200

# Optional: JSON mapping of filename to domain for chunk metadata e.g. {"statistics.pdf": "statistics", "ml-intro.pdf": "ml"}
# BOOK_DOMAIN_MAPPING = '{"statistics.pdf": "statistics"}'

# Hybrid search: dense + BM25 (alpha: 0 = only BM25, 1 = only dense)
HYBRID_SEARCH_ENABLED = true
HYBRID_SEARCH_ALPHA = 0.6
# BM25_INDEX_DIR = ""
