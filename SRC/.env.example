# ===========================================
# Fehres - Environment Configuration
# ===========================================
# Copy this file to .env and fill in real values

APP_NAME="Fehres"
APP_VERSION="0.1"

# ===========================================
# File Processing Settings
# ===========================================
FILE_ALLOWED_TYPES = ["text/plain", "application/pdf", "text/markdown", "text/x-markdown", "application/json", "text/csv", "application/vnd.openxmlformats-officedocument.wordprocessingml.document", "application/octet-stream"]
FILE_MAX_SIZE = 10
FILE_DEFAULT_CHUNK_SIZE = 512000

# ===========================================
# PostgreSQL Database
# ===========================================
POSTGRES_USER = "postgres"
POSTGRES_PASSWORD = "your-postgres-password"
POSTGRES_HOST = "localhost"
POSTGRES_PORT = "5433"
POSTGRES_MAIN_DB = "fehres"

# ===========================================
# LLM Configuration
# ===========================================
GENRATION_BACKEND = "GEMINI"
EMBEDDING_BACKEND = "GEMINI"

# API Keys (fill in your own)
OPENAI_API_KEY = "your-openai-api-key"
OPENAI_BASE_URL = "https://api.openai.com/v1"
COHERE_API_KEY = "your-cohere-api-key"
GEMINI_API_KEY = "your-gemini-api-key"
GEMINI_API_VERSION = "v1beta"
OLLAMA_BASE_URL = "http://localhost:11434"
# HUGGINGFACE_API_KEY = "hf_your_token_here"

# Model Configuration
GENRATION_MODEL_ID_LITERAL = ["gemini-2.5-flash", "command-r-plus-08-2024", "gpt-3.5-turbo-0125", "qwen3:8b", "meta-llama/Llama-2-7b-chat-hf"]
EMBEDDING_MODEL_ID_LITERAL = ["text-multilingual-embedding-002", "text-embedding-002", "text-embedding-004", "qwen3-embedding:8b", "sentence-transformers/all-MiniLM-L6-v2"]
GENRATION_MODEL_ID = "gemini-2.5-flash"
EMBEDDING_MODEL_ID = "text-embedding-004"
EMBEDDING_SIZE = 768

# Ollama (local) example:
# GENRATION_BACKEND = "OLLAMA"
# EMBEDDING_BACKEND = "OLLAMA"
# GENRATION_MODEL_ID = "qwen3:8b"
# EMBEDDING_MODEL_ID = "qwen3-embedding:8b"
# EMBEDDING_SIZE = 768

# HuggingFace example:
# GENRATION_BACKEND = "HUGGINGFACE"
# EMBEDDING_BACKEND = "HUGGINGFACE"
# HUGGINGFACE_API_KEY = "hf_your_token_here"
# GENRATION_MODEL_ID = "meta-llama/Llama-2-7b-chat-hf"
# EMBEDDING_MODEL_ID = "sentence-transformers/all-MiniLM-L6-v2"
# EMBEDDING_SIZE = 384

# Generation Parameters
INPUT_DEFUALT_MAX_CHARACTERS = 768
GENRATED_DEFUALT_MAX_OUTPUT_TOKENS = 8196
GENRATION_DEFUALT_TEMPERATURE = 0.1

# ===========================================
# Vector Database
# ===========================================
VECTORDB_BACKEND_LITERAL = ["QDRANT", "PGVECTOR"]
VECTORDB_BACKEND = "PGVECTOR"
VECTORDB_PATH = "qdrant_DB"
VECTORDB_DISTANCE_METHOD = "cosine"
VECTORDB_PGVEC_INDEX_THRESHOLD = 4

# ===========================================
# Language Settings
# ===========================================
PRIMARY_LANGUAGE = "en"
DEFUALT_LANGUAGE = "en"

LEARNING_BOOKS_CHUNK_SIZE = 2000
LEARNING_BOOKS_OVERLAP_SIZE = 200

# Optional: JSON mapping of filename to domain for chunk metadata e.g. {"statistics.pdf": "statistics", "ml-intro.pdf": "ml"}
# BOOK_DOMAIN_MAPPING = '{"statistics.pdf": "statistics"}'

# Hybrid search: dense + BM25 (alpha: 0 = only BM25, 1 = only dense)
HYBRID_SEARCH_ENABLED = true
HYBRID_SEARCH_ALPHA = 0.6
# BM25_INDEX_DIR = ""

# ===========================================
# Documentation Processing Settings
# ===========================================
DOC_CHUNK_SIZE = 1000
DOC_OVERLAP_SIZE = 200
DEFAULT_PROJECT_ID = 1

# ===========================================
# Web Scraping Configuration
# ===========================================
SCRAPING_MAX_PAGES = 1000
SCRAPING_RATE_LIMIT = 0.5
SCRAPING_USER_AGENT = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
SCRAPING_TIMEOUT = 120
# Embed batch size for streaming pipeline
SCRAPING_EMBED_BATCH_SIZE = 50
# Whether to embed chunks during scraping (1) or after (0)
SCRAPING_EMBED_DURING = 0
# Automatically embed/index after scraping completes (if not doing it during)
SCRAPING_AUTO_INDEX = 1
# Set to 1 to log first-URL debug (html_len, extracted_len, snippet)
SCRAPING_DEBUG = 0
# Use Playwright (headless Chromium) for scraping. Default 1 for JS-rendered docs.
# After uv sync, run: uv run playwright install chromium
SCRAPING_USE_BROWSER = 1
# Concurrency for scraping (when browser is disabled)
SCRAPING_CONCURRENCY = 5
# Ignore robots.txt (0 = respect, 1 = ignore). Use with care; may violate site ToS.
SCRAPING_IGNORE_ROBOTS = 0
