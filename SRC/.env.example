# ===========================================
# Fehres - Environment Configuration
# ===========================================

APP_NAME="Fehres"
APP_VERSION="0.1"

# ===========================================
# File Processing Settings
# ===========================================
FILE_ALLOWED_TYPES = ["text/plain", "application/pdf", "text/markdown", "text/x-markdown", "application/json", "text/csv", "application/vnd.openxmlformats-officedocument.wordprocessingml.document", "application/octet-stream"]
FILE_MAX_SIZE = 10
FILE_DEFAULT_CHUNK_SIZE = 512000

# ===========================================
# PostgreSQL Database
# ===========================================
POSTGRES_USER = "postgres"
POSTGRES_PASSWORD = "postgres"
POSTGRES_HOST = "pgvector"
POSTGRES_PORT = "5432"
POSTGRES_MAIN_DB = "minirag"

# ===========================================
# LLM Configuration
# ===========================================
GENRATION_BACKEND = "HUGGINGFACE"
EMBEDDING_BACKEND = "HUGGINGFACE"

# API Keys (fill in your own)
# OPENAI_API_KEY = "your-openai-api-key"
# OPENAI_BASE_URL = "https://api.openai.com/v1"
# COHERE_API_KEY = "your-cohere-api-key"
# GEMINI_API_KEY = "AIzaSyBUW9fXfkfvcL4ucmm6qYt5kunqHKmBvs0"
# GEMINI_API_VERSION = "v1beta"
HUGGINGFACE_API_KEY = "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"

# Model Configuration
GENRATION_MODEL_ID_LITERAL = ["gemini-2.0-flash", "command-r-plus-08-2024", "gpt-3.5-turbo-0125"]
EMBEDDING_MODEL_ID_LITERAL = ["text-multilingual-embedding-002", "text-embedding-002", "text-embedding-004"]
GENRATION_MODEL_ID = "Qwen/Qwen2.5-7B-Instruct"
EMBEDDING_MODEL_ID = "sentence-transformers/all-MiniLM-L6-v2"
EMBEDDING_SIZE = 384

# Generation Parameters
INPUT_DEFUALT_MAX_CHARACTERS = 768
GENRATED_DEFUALT_MAX_OUTPUT_TOKENS = 8196
GENRATION_DEFUALT_TEMPERATURE = 0.1

# ===========================================
# Vector Database
# ===========================================
VECTORDB_BACKEND_LITERAL = ["QDRANT", "PGVECTOR"]
VECTORDB_BACKEND = "PGVECTOR"
VECTORDB_PATH = "qdrant_DB"
VECTORDB_DISTANCE_METHOD = "cosine"
VECTORDB_PGVEC_INDEX_THRESHOLD = 4

# ===========================================
# Language Settings
# ===========================================
PRIMARY_LANGUAGE = "en"
DEFUALT_LANGUAGE = "en"

LEARNING_BOOKS_CHUNK_SIZE = 2000
LEARNING_BOOKS_OVERLAP_SIZE = 200

# Optional: JSON mapping of filename to domain for chunk metadata e.g. {"statistics.pdf": "statistics", "ml-intro.pdf": "ml"}
# BOOK_DOMAIN_MAPPING = '{"statistics.pdf": "statistics"}'

# Hybrid search: dense + BM25 (alpha: 0 = only BM25, 1 = only dense)
HYBRID_SEARCH_ENABLED = true
HYBRID_SEARCH_ALPHA = 0.6
# BM25_INDEX_DIR = ""

# ===========================================
# Documentation Processing Settings
# ===========================================
DOC_CHUNK_SIZE = 1000
DOC_OVERLAP_SIZE = 200
DEFAULT_PROJECT_ID = 1

# ===========================================
# Web Scraping Configuration
# ===========================================
SCRAPING_MAX_PAGES = 1000
SCRAPING_RATE_LIMIT = 0.1
SCRAPING_USER_AGENT = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
SCRAPING_TIMEOUT = 600
# Embed batch size for streaming pipeline
SCRAPING_EMBED_BATCH_SIZE = 50
SCRAPING_EMBED_DURING = 1
# Set to 1 to log first-URL debug (html_len, extracted_len, snippet)
SCRAPING_DEBUG = 0
# Use Playwright (headless Chromium) for scraping. Default 1 for JS-rendered docs.
# After uv sync, run: uv run playwright install chromium
SCRAPING_USE_BROWSER = 0
# Concurrency for scraping (when browser is disabled)
SCRAPING_CONCURRENCY = 10
# Ignore robots.txt (0 = respect, 1 = ignore). Use with care; may violate site ToS.
SCRAPING_IGNORE_ROBOTS = 1
